{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "568081f1",
   "metadata": {},
   "source": [
    "## Analise da base de dados `Beta` utilizando algoritmos de ML\n",
    "\n",
    "Neste notebook será analisado o `Beta dataset` utilizando algoritmos de ML para realizar a: \n",
    "\n",
    "1. Extração de características;\n",
    "2. Seleção de características;\n",
    "3. Classificação dos dados.\n",
    "\n",
    "### Pontos importantes do dataset\n",
    "\n",
    "- Frequências estimuladas (total de 40, com diferença de 0.2Hz uma da outra): 8.0; 8.2;...; 15.6; 15.8;\n",
    "- Taxa de amostragem: 250Hz\n",
    "\n",
    "### Analisar os \"momentos\" em que ocorrem evocação do sinal SSVEP\n",
    "1. Criar o objeto `MNE` a partir dos dados do participante;\n",
    "2. Aplicar no objeto `MNE` o filtro passa-faixa nos valores de 6 a 18 Hz;\n",
    "3. Criar cópias do objeto `MNE` com fatias de tempo menores para analisar momentos que ocorrem estimulos ou não (verificar artigo);\n",
    "\n",
    "> 0.0 - 0.5 segundos e 2.5 - 3.0 segundos, ocorre apenas ruído; <br/>\n",
    " 0.5 - 2.5 segundos, ocorre sinal SSVEP (com ruídos)\n",
    " \n",
    "4. Com os sinais separados em objetos `MNE`, aplicar a `FFT`, para que seja possível plotar gráficos que contenham (ou não) as informações:\n",
    "- Os dados devem ser plotados do domínio da frequência (após a transformada de Fourier). O `FFT` pode ser realizado pela biblioteca `scipy.fft`.\n",
    "- Deve ser observado que as janelas (a) com ruído não aparecerão de fato o sinal SSVEP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "541d82b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import matplotlib as plt\n",
    "import mne\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# beta = loadmat(f\"../../datasets/beta/S13.mat\")\n",
    "beta = np.load(f\"../../datasets/beta/data_beta.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a79272",
   "metadata": {},
   "source": [
    "### Extração de características\n",
    "\n",
    "Uma característica importante de acordo com o artigo base do dataset `Beta` é o *signal-to-noise ratio* (SNR).\n",
    "\n",
    "> Incluir equação SNR\n",
    "\n",
    "Ao finalizar essa etapa, será obtido um vetor de características. Essas podem ser:\n",
    "- `SNR` (obrigatória);\n",
    "- Maior valor espectral (FFT em vez do compute_psd);\n",
    "- Média dos valores espectrais (FFT).\n",
    "\n",
    "Dimensionalidade dos dados será explicada da seguinte forma:\n",
    "- `40, 4, 64, 750` -> 40 targets, 4 trials, 64 canais, 750 valores \n",
    "- `160, 64 (SNR) + 64 (media) + 64 (maior) ...` Resultando em `160, 192` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9359f0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/vinicius/Documents/RP_SSVEP/ssvep/src/beta/mne_data_beta.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    2996.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "160 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>10.0: 4<br/>10.2: 4<br/>10.4: 4<br/>10.6: 4<br/>10.8: 4<br/>11.0: 4<br/>11.2: 4<br/>11.4: 4<br/>11.6: 4<br/>11.8: 4<br/>12.0: 4<br/>12.2: 4<br/>12.4: 4<br/>12.600000000000001: 4<br/>12.8: 4<br/>13.0: 4<br/>13.200000000000001: 4<br/>13.4: 4<br/>13.600000000000001: 4<br/>13.8: 4<br/>14.0: 4<br/>14.200000000000001: 4<br/>14.4: 4<br/>14.600000000000001: 4<br/>14.8: 4<br/>15.0: 4<br/>15.200000000000001: 4<br/>15.4: 4<br/>15.600000000000001: 4<br/>15.8: 4<br/>8.0: 4<br/>8.2: 4<br/>8.4: 4<br/>8.6: 4<br/>8.799999999999999: 4<br/>9.0: 4<br/>9.2: 4<br/>9.4: 4<br/>9.6: 4<br/>9.8: 4</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>0.000 – 2.996 s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>off</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<EpochsFIF |  160 events (all good), 0 – 2.996 s, baseline off, ~58.7 MB, data loaded,\n",
       " '8.0': 4\n",
       " '8.2': 4\n",
       " '8.4': 4\n",
       " '8.6': 4\n",
       " '8.799999999999999': 4\n",
       " '9.0': 4\n",
       " '9.2': 4\n",
       " '9.4': 4\n",
       " '9.6': 4\n",
       " '9.8': 4\n",
       " and 30 more events ...>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = beta['data'][0][0][0]\n",
    "# y = beta['data'][0][0][1][0][0][4][0]\n",
    "\n",
    "# X_beta = np.array(np.transpose(X, (3, 2, 0, 1)))\n",
    "# print(X_beta.shape)\n",
    "\n",
    "# X_beta = X_beta.reshape(X_beta.shape[0] * X_beta.shape[1], X_beta.shape[2], X_beta.shape[3])\n",
    "# print(X_beta.shape)\n",
    "\n",
    "# print(\"\\nLabels:\")\n",
    "# print(y.shape)\n",
    "# print(y)\n",
    "\n",
    "\n",
    "mne_data = mne.read_epochs(\"mne_data_beta.fif\")\n",
    "beta = mne_data.get_data()\n",
    "mne_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f392046",
   "metadata": {},
   "source": [
    "> Agora iremos estimar o ruído de fundo, para calcular posteriormente o `narrow SNR` e o `wide-band SNR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef6688b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30465.602510101286"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimando o ruído de fundo\n",
    "\n",
    "# intervalos de tempo sem estímulo (0 a 0,5 segundos e 2,5 a 3 segundos)\n",
    "base_start = 0\n",
    "base_end = 125\n",
    "rest_start = 625\n",
    "rest_end = 750\n",
    "\n",
    "# armazena uma lista com as médias de potência para cada canal\n",
    "noise_power = []\n",
    "\n",
    "# consideramos a primeira amostra (1º target, 1º trial)\n",
    "# for channel_data in X_beta[0, :, :]:\n",
    "for channel_data in beta[0, :, :]:\n",
    "    fft_result = np.fft.fft(channel_data)\n",
    "    \n",
    "    # densidade espectral de potência (PSD)\n",
    "    psd = np.abs(fft_result) ** 2\n",
    "    \n",
    "    # média da potência nos intervalos de tempo sem estímulo\n",
    "    base_power = np.mean(psd[base_start:base_end])\n",
    "    rest_power = np.mean(psd[rest_start:rest_end])\n",
    "    \n",
    "    # média das duas médias de potência obtidas anteriormente\n",
    "    mean_noise_power = (base_power + rest_power) / 2\n",
    "    noise_power.append(mean_noise_power)\n",
    "    \n",
    "#média das médias de potência de todos os canais para estimar o ruído de fundo\n",
    "estimated_background_noise = np.mean(noise_power)\n",
    "estimated_background_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "429c193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Estimando o ruído de fundo\n",
    "\n",
    "# # intervalos de tempo sem estímulo (0 a 0,5 segundos e 2,5 a 3 segundos)\n",
    "# ini_ruido = mne_data.copy().crop(tmin=0.0, tmax=0.5)\n",
    "# meio_ruido = mne_data.copy().crop(tmin=0.5, tmax=2.5)\n",
    "# fim_ruido = mne_data.copy().crop(tmin=2.5, tmax=3.0)\n",
    "\n",
    "# # consideramos a primeira amostra (1º target, 1º trial)\n",
    "# fft_ini_result = np.fft.fft(ini_ruido)\n",
    "# fft_fim_result = np.fft.fft(fim_ruido)\n",
    "\n",
    "# # densidade espectral de potência (PSD)\n",
    "# psd_ini = np.abs(fft_ini_result) ** 2\n",
    "# psd_fim = np.abs(fft_fim_result) ** 2\n",
    "\n",
    "# # média da potência nos intervalos de tempo sem estímulo\n",
    "# base_power = np.mean(psd_ini, axis=-1)\n",
    "# rest_power = np.mean(psd_fim, axis=-1)\n",
    "\n",
    "# # média das duas médias de potência obtidas anteriormente\n",
    "# mean_noise_power = np.mean([base_power + rest_power])\n",
    "    \n",
    "# #média das médias de potência de todos os canais para estimar o ruído de fundo\n",
    "# mean_noise_power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c015c681",
   "metadata": {},
   "source": [
    "> Antes de calcular os SNRs, precisamos obter as amplitudes alvo por meio dos dados EEG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b775611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 64, 40)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "sr = 250\n",
    "\n",
    "# frequências alvo\n",
    "target_frequencies = np.arange(8, 16, 0.2)\n",
    "\n",
    "# lista para armazenar as amplitudes nas frequências alvo\n",
    "target_amplitudes = []\n",
    "\n",
    "# for channel_data in X_beta[0, :, :]:\n",
    "for channel_data in mne_data.get_data():\n",
    "    target = []\n",
    "    for eletrodo in channel_data:\n",
    "        # fft_result = np.fft.fft(channel_data)\n",
    "        fft_result = np.fft.fft(eletrodo)\n",
    "        psd = np.abs(fft_result) ** 2\n",
    "        frequencies = np.fft.fftfreq(len(fft_result), 1 / sr)\n",
    "        target_amplitudes_trial = []\n",
    "        for target_frequency in target_frequencies:\n",
    "            # encontrando o índice da frequência alvo no espectro de frequência\n",
    "            index = np.argmin(np.abs(frequencies - target_frequency))\n",
    "            # amplitude na frequência alvo\n",
    "            amplitude = np.sqrt(psd[index])\n",
    "            target_amplitudes_trial.append(amplitude)\n",
    "        \n",
    "        target.append(target_amplitudes_trial)\n",
    "\n",
    "    target_amplitudes.append(target)\n",
    "    \n",
    "target_amplitudes = np.array(target_amplitudes)\n",
    "target_amplitudes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03674497",
   "metadata": {},
   "source": [
    "Vamos calcular o SNR de \"banda estreita\". Pode ser observado pela seguinte equação:\n",
    "\n",
    "$SNR_{banda\\ estreita} = 10 \\cdot \\log_{10}\\left(\\frac{\\text{energia total do espectro}}{\\text{média das amplitudes nas frequências vizinhas}}\\right)$\n",
    "\n",
    "Já o SNR de banda larga é definido da seguinte forma:\n",
    "\n",
    "$SNR_{banda\\ larga} = 10 \\cdot \\log_{10}\\left(\\frac{\\text{energia total do espectro}}{\\text{energia total do espectro de amplitude}}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fb75707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 64, 40)\n",
      "(160, 64, 40)\n",
      "\n",
      "(160, 64, 80)\n"
     ]
    }
   ],
   "source": [
    "# forçando (estragando) valor de \"estimated_background_noise\" para não sobrar valores negativos\n",
    "estimated_background_noise = 1.\n",
    "target_amplitudes_adjusted = target_amplitudes - estimated_background_noise\n",
    "\n",
    "# subtraindo o ruído de fundo das amplitudes\n",
    "narrow_band_SNR = 10 * np.log10(target_amplitudes_adjusted / estimated_background_noise)\n",
    "# print(narrow_band_SNR)\n",
    "print(narrow_band_SNR.shape)\n",
    "\n",
    "total_power = np.sum(target_amplitudes_adjusted)\n",
    "wide_band_SNR = 10 * np.log10(target_amplitudes_adjusted / total_power)\n",
    "# print(wide_band_SNR)\n",
    "print(wide_band_SNR.shape)\n",
    "\n",
    "\n",
    "X = np.array([narrow_band_SNR, wide_band_SNR])\n",
    "X = X.swapaxes(0, 1)\n",
    "X = X.swapaxes(1, 2)\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2] * X.shape[3])\n",
    "print()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea1709d",
   "metadata": {},
   "source": [
    "Ao final desta etapa, será obtido um vetor de características. Estas podem ser:\n",
    "- `narrow SNR` (obrigatória);\n",
    "- `wide-band SNR` (obrigatória);\n",
    "- Maior valor espectral (FFT);\n",
    "- Média dos valores espectrais (FFT).\n",
    "\n",
    "> Dimensionalidade dos dados será explicada da seguinte forma:\n",
    "\n",
    "`40, 4, 64, 750` -> 40 targets, 4 trials, 64 canais e 750 valores `160, 64 (SNR) + 64 (média) + 64 (maior) ...`\n",
    "Resultando em `(160, 192)`.\n",
    "\n",
    "`(160, 64, 750)` = 2 * `(160, 64, 40)` = `(160, 64, 80)` => (reshape) `(160, 64)`\n",
    "\n",
    "reshape => `(160, 64, 80)`\n",
    "\n",
    "> (1) **Seleção de características (MANUAL)**\n",
    "\n",
    "Remover os eletrodos não listados no artigo => `(160, 9, 80)` => reshape `(160, 720)`\n",
    "\n",
    "> (2) Vetor de característica para a **seleção de características RFE**\n",
    "\n",
    "`(160, 64, 80)` => reshape => `(160, 5120)`. Após aplicar o RFE, retorna  `(160, N)`\n",
    "\n",
    "> (3) Aplicar SVM (kernel='linear'), nas duas seleções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1bbaa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 9, 80)\n",
      "(160, 720)\n"
     ]
    }
   ],
   "source": [
    "# 1 - Seleção de características (MANUAL)\n",
    "\n",
    "ch = np.load(\"../../datasets/beta/channels.npy\")\n",
    "\n",
    "best_ch = ['PZ', 'PO3', 'PO5', 'PO4', 'PO6', 'POZ', 'O1', 'OZ', 'O2']\n",
    "index_remove = np.where(np.isin(ch, best_ch, invert=True))\n",
    "\n",
    "X_selected_ch = np.delete(X, index_remove, axis=1)\n",
    "print(X_selected_ch.shape)\n",
    "\n",
    "X_selected_ch = X_selected_ch.reshape(X_selected_ch.shape[0], X_selected_ch.shape[1] * X_selected_ch.shape[2])\n",
    "print(X_selected_ch.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb5b75c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 5120)\n"
     ]
    }
   ],
   "source": [
    "# 2 - Vetor de característica para a seleção de características RFE\n",
    "\n",
    "X_reshape = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\n",
    "print(X_reshape.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fa2933",
   "metadata": {},
   "source": [
    "### Seleção de características e classificação\n",
    "\n",
    "Como existem diversos eletrodos (canais) que não obtém sinal SSVEP, podemos extrair as características que não contribuem para a classificação dos dados.\n",
    "\n",
    "Podemos utilizar o método `RFE` (*Recursive Feature Elimination*) aplicando por meio de `sklearn.feature_selection.RFE`, aprimorando o parâmetro `n_features_to_select` até obter o melhor resultado de classificação.\n",
    "\n",
    "Para a classificação propriamente dita, é considerado o uso do método `SVM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97e9ff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_estatisticas(resultados):\n",
    "    return np.mean(resultados), np.std(resultados), np.min(resultados), np.max(resultados)\n",
    "\n",
    "def imprimir_estatisticas(resultados):\n",
    "    media, desvio, mini, maxi = calcular_estatisticas(resultados)\n",
    "    print(\"Resultados: %.2f +- %.2f, min: %.2f, max: %.2f\" % (media, desvio, mini, maxi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8c9f5acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "#Cs e gammas são listas com os valores a serem avaliados para os respectivos parâmetros.\n",
    "def selecionar_melhor_svm(Cs, gammas, X_treino : np.ndarray, X_val : np.ndarray, \n",
    "                          y_treino : np.ndarray, y_val : np.ndarray, n_jobs=4):\n",
    "    \n",
    "    def treinar_svm(C, gamma, X_treino, X_val, y_treino, y_val):\n",
    "        svm = SVC(C=C, gamma=gamma)\n",
    "        svm.fit(X_treino, y_treino)\n",
    "        pred = svm.predict(X_val)\n",
    "        return accuracy_score(y_val, pred)\n",
    "    \n",
    "    #gera todas as combinações de parametros C e gamma, de acordo com as listas de valores recebidas por parametro.\n",
    "    #Na prática faz o produto cartesiano entre Cs e gammas.\n",
    "    combinacoes_parametros = list(itertools.product(Cs, gammas))\n",
    "    \n",
    "    #Treinar modelos com todas as combinações de C e gamma\n",
    "    acuracias_val = Parallel(n_jobs=n_jobs)(delayed(treinar_svm)\n",
    "                                       (c, g, X_treino, X_val, y_treino, y_val) for c, g in combinacoes_parametros)       \n",
    "    \n",
    "    melhor_val = max(acuracias_val)\n",
    "    #Encontrar a combinação que levou ao melhor resultado no conjunto de validação\n",
    "    melhor_comb = combinacoes_parametros[np.argmax(acuracias_val)]   \n",
    "    melhor_c = melhor_comb[0]\n",
    "    melhor_gamma = melhor_comb[1]\n",
    "    \n",
    "    #Treinar uma SVM com todos os dados de treino e validação usando a melhor combinação de C e gamma.\n",
    "    svm = SVC(C=melhor_c, gamma=melhor_gamma)\n",
    "    svm.fit(np.vstack((X_treino, X_val)), [*y_treino, *y_val])\n",
    "\n",
    "    return svm, melhor_comb, melhor_val\n",
    "\n",
    "#Implementa a validação cruzada para avaliar o desempenho da SVM na base de dados com as instâncias X e as saídas y.\n",
    "#cv_splits indica o número de partições que devem ser criadas.\n",
    "#Cs é a lista com os valores C que devem ser avaliados na busca exaustiva de parametros para a SVM.\n",
    "#gammas s é a lista com os valores gamma que devem ser avaliados na busca exaustiva de parametros para a SVM.\n",
    "def do_cv_svm(X, y, cv_splits, Cs=[1], gammas=['scale']):\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=1)\n",
    "\n",
    "    acuracias = []\n",
    "    \n",
    "    pgb = tqdm(total=cv_splits, desc='Folds avaliados')\n",
    "    \n",
    "    for treino_idx, teste_idx in skf.split(X, y):\n",
    "\n",
    "        X_treino = X[treino_idx]\n",
    "        y_treino = y[treino_idx]\n",
    "\n",
    "        X_teste = X[teste_idx]\n",
    "        y_teste = y[teste_idx]\n",
    "\n",
    "        X_treino, X_val, y_treino, y_val = train_test_split(X_treino, y_treino, stratify=y_treino, test_size=0.35, random_state=1)\n",
    "\n",
    "        ss = StandardScaler()\n",
    "        ss.fit(X_treino)\n",
    "        X_treino = ss.transform(X_treino)\n",
    "        X_teste = ss.transform(X_teste)\n",
    "        X_val = ss.transform(X_val)\n",
    "\n",
    "        svm, _, _ = selecionar_melhor_svm(Cs, gammas, X_treino, X_val, y_treino, y_val)\n",
    "        pred = svm.predict(X_teste)\n",
    "\n",
    "        acuracias.append(accuracy_score(y_teste, pred))\n",
    "        \n",
    "        pgb.update(1)\n",
    "        \n",
    "    pgb.close()\n",
    "    \n",
    "    return acuracias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ca5474ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 9.38 %\n"
     ]
    }
   ],
   "source": [
    "X = StandardScaler().fit_transform(X_selected_ch)\n",
    "labels = np.load(\"../../datasets/beta/labels_beta.npy\")\n",
    "y = LabelEncoder().fit_transform(labels)\n",
    "\n",
    "# print(X.shape)\n",
    "\n",
    "# svm = do_cv_svm(X, y, 10, Cs=[1, 10, 100, 1000], gammas=['auto', 'scale'])\n",
    "# imprimir_estatisticas(svm)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Preencher valores NaN com a media da coluna\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.fit_transform(X_test)\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10).fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: %.2f %%\" % (accuracy_score(y_test, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1b6fd3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher valores NaN com a media da coluna\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_reshape = imputer.fit_transform(X_reshape)\n",
    "\n",
    "X_norm = MinMaxScaler().fit_transform(X_reshape)\n",
    "\n",
    "# svm_model_full = SVC(kernel='linear', C=1, random_state=0, probability=True)\n",
    "rfe = RFECV(SVC(kernel=\"linear\", C=1, random_state=0), min_features_to_select=10, step=5, cv=4, scoring='accuracy')\n",
    "X_full = rfe.fit_transform(X_norm, y)\n",
    "\n",
    "# rfecv = RFECV(estimator=SVC(kernel='linear'), step=1, min_features_to_select=1)\n",
    "# X_full = rfecv.fit_transform(X_reshape, y)\n",
    "# X_full.shape\n",
    "# selector = RFE(estimator=estimator, n_features_to_select=1, step=0.001).fit(X_reshape, y)\n",
    "# selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c8d93a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 35)\n",
      "Accuracy: 12.50 %\n"
     ]
    }
   ],
   "source": [
    "# X_full = rfe.fit_transform(X_reshape, y)\n",
    "print(X_full.shape)\n",
    "\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X_full, y, test_size=0.2, random_state=0)\n",
    "\n",
    "svm_full_model = SVC(kernel='linear', C=1, random_state=42, probability=True).fit(X_train_full, y_train_full)\n",
    "y_full_pred = svm_full_model.predict(X_test_full)\n",
    "\n",
    "print(\"Accuracy: %.2f %%\" % (accuracy_score(y_test_full, y_full_pred) * 100))\n",
    "\n",
    "# X_full.n_features_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
